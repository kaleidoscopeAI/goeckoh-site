

// ========================================================
// FILE: rust_core/Cargo.toml
// ========================================================
[package]
name = "bio_audio"
version = "5.0.0"
edition = "2021"

[lib]
name = "bio_audio"
crate-type = ["cdylib"]

[dependencies]
# Pinning to a recent, stable version of pyo3
pyo3 = { version = "0.21.2", features = ["extension-module"] }
rand = "0.8.5"


// ========================================================
// FILE: rust_core/src/lib.rs
// ========================================================
use pyo3::prelude::*;
use std::f64::consts::PI;
use rand;

/// THE BIO-ACOUSTIC ENGINE
/// Production-ready struct acting as a singleton for synthesis.
#[pyclass]
struct BioAcousticEngine {
    sample_rate: f64,
}

#[pymethods]
#[allow(non_local_definitions)]
impl BioAcousticEngine {
    #[new]
    fn new() -> Self {
        BioAcousticEngine { sample_rate: 22050.0 }
    }

    /// Advanced bio-acoustic synthesis with real physics modeling
    /// Generates therapeutic audio based on emotional state
    fn synthesize(&self, text_stimulus_len: usize, arousal_state: f64) -> Vec<f32> {
        // Validate and clamp inputs for safety
        let safe_arousal = arousal_state.max(0.0).min(1.0);
        let duration = (text_stimulus_len as f64 * 0.08).max(0.3).min(4.0);
        let num_samples = (self.sample_rate * duration) as usize;
        let mut buffer = Vec::with_capacity(num_samples);

        // Multi-layer synthesis approach
        // 1. Base frequency with biological resonance
        let base_f0 = 130.0 + (120.0 * (1.0 - safe_arousal)); // 130-250Hz range
        
        // 2. Formant structure for vocal quality
        let f1 = 800.0 + (200.0 * safe_arousal); // First formant
        let f2 = 1500.0 + (300.0 * safe_arousal); // Second formant
        
        // 3. Tremor and vibrato parameters
        let vibrato_rate = 5.0 + (2.0 * safe_arousal); // 5-7 Hz
        let vibrato_depth = if safe_arousal > 0.7 { 0.01 } else { 0.03 + (0.02 * safe_arousal) };
        
        // 4. Noise component for naturalness
        let noise_level = 0.02 + (0.03 * safe_arousal);
        
        let mut phase_base = 0.0;
        let mut phase_f1 = 0.0;
        let mut phase_f2 = 0.0;
        let mut vibrato_phase = 0.0;
        
        for i in 0..num_samples {
            let _t = i as f64 / self.sample_rate;
            
            // Vibrato modulation
            vibrato_phase += (2.0 * PI * vibrato_rate) / self.sample_rate;
            let vibrato = 1.0 + (vibrato_phase.sin() * vibrato_depth);
            
            // Apply vibrato to base frequency
            let modulated_f0 = base_f0 * vibrato;
            
            // Update phases
            phase_base += (2.0 * PI * modulated_f0) / self.sample_rate;
            phase_f1 += (2.0 * PI * f1) / self.sample_rate;
            phase_f2 += (2.0 * PI * f2) / self.sample_rate;
            
            // Generate harmonic components
            let fundamental = phase_base.sin();
            let formant1 = (phase_f1.sin() * 0.3) * (1.0 + 0.5 * fundamental);
            let formant2 = (phase_f2.sin() * 0.2) * (1.0 + 0.3 * fundamental);
            
            // Add controlled noise for naturalness
            let noise = (rand::random::<f64>() - 0.5) * noise_level;
            
            // Combine components with biological weighting
            let sample = fundamental + formant1 + formant2 + noise;
            
            // ADSR envelope with therapeutic shaping
            let attack = 0.05; // 50ms attack
            let sustain = 0.7; // 70% sustain level
            let release_samples = (0.1 * self.sample_rate) as usize; // 100ms release
            
            let env = if i < (attack * self.sample_rate) as usize {
                i as f64 / (attack * self.sample_rate)
            } else if i > num_samples - release_samples {
                let release_progress = (num_samples - i) as f64 / release_samples as f64;
                sustain * release_progress
            } else {
                sustain
            };
            
            // Soft clipping for safety
            let soft_clipped = sample.tanh() * 0.8;
            buffer.push((soft_clipped * env) as f32);
        }
        
        buffer
    }

    /// Real-time audio modulation for emotional regulation
    fn modulate_pcm(&self, input_samples: Vec<f32>, arousal_state: f64) -> Vec<f32> {
        let mut output = Vec::with_capacity(input_samples.len());
        let safe_arousal = arousal_state.max(0.0).min(1.0);
        
        // Dynamic modulation parameters based on emotional state
        let compression_ratio = 1.0 + (2.0 * safe_arousal); // 1:1 to 3:1 compression
        let low_freq_gain = 1.0 + (0.5 * (1.0 - safe_arousal)); // Boost lows when calm
        let high_freq_gain = 1.0 - (0.3 * safe_arousal); // Cut highs when aroused
        
        // Simple low-pass filter state
        let mut prev_sample = 0.0;
        let filter_coeff = if safe_arousal > 0.6 { 0.9 } else { 0.7 }; // More filtering when stressed
        
        for (i, sample) in input_samples.iter().enumerate() {
            let _t = i as f64 / self.sample_rate;
            
            // Apply dynamic range compression for safety
            let compressed = if sample.abs() > 0.5 {
                sample.signum() * (0.5 + (sample.abs() - 0.5) / compression_ratio as f32)
            } else {
                *sample
            };
            
            // Apply frequency shaping through simple filtering
            let filtered = prev_sample * filter_coeff + compressed * (1.0 - filter_coeff);
            prev_sample = filtered;
            
            // Apply frequency-dependent gain
            let shaped = filtered * low_freq_gain as f32 * high_freq_gain as f32;
            
            // Safety limiting
            let limited = shaped.max(-0.9).min(0.9);
            output.push(limited as f32);
        }
        
        output
    }
}

/// The Module Wrapper exposed to Python
#[pymodule]
fn bio_audio(_py: Python<'_>, m: &Bound<'_, PyModule>) -> PyResult<()> {
    m.add_class::<BioAcousticEngine>()?;
    Ok(())
}


// ========================================================
// FILE: rust_core/src/bio_engine_v1.rs
// ========================================================
use pyo3::prelude::*;
use std::f64::consts::PI;
use rand;

#[pyclass]
struct BioAcousticEngine {
    sample_rate: f64,
}

#[pymethods]
impl BioAcousticEngine {
    #[new]
    fn new() -> Self {
        BioAcousticEngine { sample_rate: 22050.0 }
    }

    /// Advanced bio-acoustic synthesis with real physics modeling
    /// Generates therapeutic audio based on emotional state
    fn synthesize(&self, text_len: usize, arousal_state: f64) -> Vec<f32> {
        // Validate and clamp inputs for safety
        let safe_arousal = arousal_state.max(0.0).min(1.0);
        let duration = (text_len as f64 * 0.08).max(0.3).min(4.0);
        let num_samples = (self.sample_rate * duration) as usize;
        let mut buffer = Vec::with_capacity(num_samples);

        // Multi-layer synthesis approach
        // 1. Base frequency with biological resonance
        let base_f0 = 130.0 + (120.0 * (1.0 - safe_arousal)); // 130-250Hz range
        
        // 2. Formant structure for vocal quality
        let f1 = 800.0 + (200.0 * safe_arousal); // First formant
        let f2 = 1500.0 + (300.0 * safe_arousal); // Second formant
        
        // 3. Tremor and vibrato parameters
        let vibrato_rate = 5.0 + (2.0 * safe_arousal); // 5-7 Hz
        let vibrato_depth = if safe_arousal > 0.7 { 0.01 } else { 0.03 + (0.02 * safe_arousal) };
        
        // 4. Noise component for naturalness
        let noise_level = 0.02 + (0.03 * safe_arousal);
        
        let mut phase_base = 0.0;
        let mut phase_f1 = 0.0;
        let mut phase_f2 = 0.0;
        let mut vibrato_phase = 0.0;
        
        for i in 0..num_samples {
            let t = i as f64 / self.sample_rate;
            
            // Vibrato modulation
            vibrato_phase += (2.0 * PI * vibrato_rate) / self.sample_rate;
            let vibrato = 1.0 + (vibrato_phase.sin() * vibrato_depth);
            
            // Apply vibrato to base frequency
            let modulated_f0 = base_f0 * vibrato;
            
            // Update phases
            phase_base += (2.0 * PI * modulated_f0) / self.sample_rate;
            phase_f1 += (2.0 * PI * f1) / self.sample_rate;
            phase_f2 += (2.0 * PI * f2) / self.sample_rate;
            
            // Generate harmonic components
            let fundamental = phase_base.sin();
            let formant1 = (phase_f1.sin() * 0.3) * (1.0 + 0.5 * fundamental);
            let formant2 = (phase_f2.sin() * 0.2) * (1.0 + 0.3 * fundamental);
            
            // Add controlled noise for naturalness
            let noise = (rand::random::<f64>() - 0.5) * noise_level;
            
            // Combine components with biological weighting
            let sample = fundamental + formant1 + formant2 + noise;
            
            // ADSR envelope with therapeutic shaping
            let attack = 0.05; // 50ms attack
            let sustain = 0.7; // 70% sustain level
            let release_samples = (0.1 * self.sample_rate) as usize; // 100ms release
            
            let env = if i < (attack * self.sample_rate) as usize {
                i as f64 / (attack * self.sample_rate)
            } else if i > num_samples - release_samples {
                let release_progress = (num_samples - i) as f64 / release_samples as f64;
                sustain * release_progress
            } else {
                sustain
            };
            
            // Soft clipping for safety
            let soft_clipped = sample.tanh() * 0.8;
            buffer.push((soft_clipped * env) as f32);
        }
        
        buffer
    }

    /// Real-time audio modulation for emotional regulation
    fn modulate_pcm(&self, input_samples: Vec<f32>, arousal_state: f64) -> Vec<f32> {
        let mut output = Vec::with_capacity(input_samples.len());
        let safe_arousal = arousal_state.max(0.0).min(1.0);
        
        // Dynamic modulation parameters based on emotional state
        let compression_ratio = 1.0 + (2.0 * safe_arousal); // 1:1 to 3:1 compression
        let low_freq_gain = 1.0 + (0.5 * (1.0 - safe_arousal)); // Boost lows when calm
        let high_freq_gain = 1.0 - (0.3 * safe_arousal); // Cut highs when aroused
        
        // Simple low-pass filter state
        let mut prev_sample = 0.0;
        let filter_coeff = if safe_arousal > 0.6 { 0.9 } else { 0.7 }; // More filtering when stressed
        
        for (i, sample) in input_samples.iter().enumerate() {
            let t = i as f64 / self.sample_rate;
            
            // Apply dynamic range compression for safety
            let compressed = if sample.abs() > 0.5 {
                sample.signum() * (0.5 + (sample.abs() - 0.5) / compression_ratio)
            } else {
                *sample
            };
            
            // Apply frequency shaping through simple filtering
            let filtered = prev_sample * filter_coeff + compressed * (1.0 - filter_coeff);
            prev_sample = filtered;
            
            // Apply frequency-dependent gain
            let shaped = filtered * low_freq_gain * high_freq_gain;
            
            // Safety limiting
            let limited = shaped.max(-0.9).min(0.9);
            output.push(limited as f32);
        }
        
        output
    }
}

#[pymodule]
fn bio_audio(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_class::<BioAcousticEngine>()?;
    Ok(())
}

// ========================================================
// FILE: rust_core/src/bio_engine_v2.rs
// ========================================================
use pyo3::prelude::*;
use std::f64::consts::PI;

#[pyclass]
struct BioEngine {
    sample_rate: f64,
}

#[pymethods]
impl BioEngine {
    #[new]
    fn new() -> Self {
        BioEngine { sample_rate: 22050.0 }
    }

    fn synthesize(&self, text_len: usize, arousal_state: f64) -> Vec<f32> {
        if text_len == 0 { return vec![0.0]; } // Safety check

        // Physics Logic
        let safe_arousal = arousal_state.clamp(0.0, 1.0);
        let duration = (text_len as f64 * 0.1).clamp(0.5, 5.0);
        let num_samples = (self.sample_rate * duration) as usize;
        
        let mut buffer = Vec::with_capacity(num_samples);
        let f0 = 150.0 - (safe_arousal * 20.0); 

        // Robotic damping during Meltdown (High stress)
        let jitter_intensity = if safe_arousal > 0.6 { 0.001 } else { 0.02 };
        
        let mut phase = 0.0;
        
        for i in 0..num_samples {
            let t = i as f64 / self.sample_rate;
            let jitter = (t * 30.0).sin() * jitter_intensity;
            let inst_f0 = f0 * (1.0 + jitter);
            
            phase += (2.0 * PI * inst_f0) / self.sample_rate;
            if phase > 2.0 * PI { phase -= 2.0 * PI; }

            // Soft Sawtooth (Rich Harmonic Content)
            let sample = 0.8 * phase.sin() - 0.2 * (2.0 * phase).sin();
            
            // Linear Attack/Decay Envelope
            let env = if i < 1000 { 
                i as f64 / 1000.0 
            } else if i > num_samples - 1000 { 
                (num_samples - i) as f64 / 1000.0 
            } else { 
                1.0 
            };

            buffer.push((sample * env) as f32);
        }
        
        buffer
    }

    fn modulate_pcm(&self, input_samples: Vec<f32>, arousal_state: f64) -> Vec<f32> {
        if input_samples.is_empty() { return vec![]; }

        let mut output = Vec::with_capacity(input_samples.len());
        let mut phase = 0.0;
        let safe_arousal = arousal_state.clamp(0.0, 1.0);

        // Tremor dynamics
        let tremolo_speed = if safe_arousal > 0.6 { 20.0 } else { 5.0 };
        let tremolo_depth = if safe_arousal > 0.8 { 0.0 } else { 0.15 * safe_arousal };

        for (i, &sample) in input_samples.iter().enumerate() {
            phase += tremolo_speed / self.sample_rate;
            if phase > 2.0 * PI { phase -= 2.0 * PI; }

            let amp_mod = 1.0 + (phase.sin() * tremolo_depth);
            
            // GCL Volume Compression (Safety Gating)
            let processed_sample = if safe_arousal > 0.8 {
                sample * 0.8 
            } else {
                sample
            };

            output.push(processed_sample * amp_mod as f32);
        }
        output
    }
}

#[pymodule]
fn bio_audio(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_class::<BioEngine>()?;
    Ok(())
}