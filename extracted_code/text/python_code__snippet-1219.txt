url = link.url.split("#", 1)[0]

# Check for VCS schemes that do not support lookup as web pages.
vcs_scheme = _match_vcs_scheme(url)
if vcs_scheme:
    logger.warning(
        "Cannot look at %s URL %s because it does not support lookup as web pages.",
        vcs_scheme,
        link,
    )
    return None

# Tack index.html onto file:// URLs that point to directories
scheme, _, path, _, _, _ = urllib.parse.urlparse(url)
if scheme == "file" and os.path.isdir(urllib.request.url2pathname(path)):
    # add trailing slash if not present so urljoin doesn't trim
    # final segment
    if not url.endswith("/"):
        url += "/"
    # TODO: In the future, it would be nice if pip supported PEP 691
    #       style responses in the file:// URLs, however there's no
    #       standard file extension for application/vnd.pypi.simple.v1+json
    #       so we'll need to come up with something on our own.
    url = urllib.parse.urljoin(url, "index.html")
    logger.debug(" file: URL is directory, getting %s", url)

try:
    resp = _get_simple_response(url, session=session)
except _NotHTTP:
    logger.warning(
        "Skipping page %s because it looks like an archive, and cannot "
        "be checked by a HTTP HEAD request.",
        link,
    )
except _NotAPIContent as exc:
    logger.warning(
        "Skipping page %s because the %s request got Content-Type: %s. "
        "The only supported Content-Types are application/vnd.pypi.simple.v1+json, "
        "application/vnd.pypi.simple.v1+html, and text/html",
        link,
        exc.request_desc,
        exc.content_type,
    )
except NetworkConnectionError as exc:
    _handle_get_simple_fail(link, exc)
except RetryError as exc:
    _handle_get_simple_fail(link, exc)
except SSLError as exc:
    reason = "There was a problem confirming the ssl certificate: "
    reason += str(exc)
    _handle_get_simple_fail(link, reason, meth=logger.info)
except requests.ConnectionError as exc:
    _handle_get_simple_fail(link, f"connection error: {exc}")
except requests.Timeout:
    _handle_get_simple_fail(link, "timed out")
else:
    return _make_index_content(resp, cache_link_parsing=link.cache_link_parsing)
return None


